{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1caeba6",
   "metadata": {},
   "source": [
    "# Programming Exercise 1\n",
    "\n",
    "## Part 1\n",
    "\n",
    "In this programming problem and the next you'll code up the greedy algorithms from lecture for minimizing the weighted sum of completion times..\n",
    "\n",
    "Download the text file below.\n",
    "\n",
    "(See C3W1_jobs.txt)\n",
    "\n",
    "This file describes a set of jobs with positive and integral weights and lengths.  It has the format\n",
    "\n",
    "[number_of_jobs]\n",
    "\n",
    "[job_1_weight] [job_1_length]\n",
    "\n",
    "[job_2_weight] [job_2_length]\n",
    "\n",
    "...\n",
    "\n",
    "For example, the third line of the file is \"74 59\", indicating that the second job has weight 74 and length 59.\n",
    "\n",
    "You should NOT assume that edge weights or lengths are distinct.\n",
    "\n",
    "Your task in this problem is to run the greedy algorithm that schedules jobs in decreasing order of the difference (weight - length).  Recall from lecture that this algorithm is not always optimal.  IMPORTANT: if two jobs have equal difference (weight - length), you should schedule the job with higher weight first.  Beware: if you break ties in a different way, you are likely to get the wrong answer.  You should report the sum of weighted completion times of the resulting schedule --- a positive integer --- in the box below. \n",
    "\n",
    "ADVICE: If you get the wrong answer, try out some small test cases to debug your algorithm (and post your test cases to the discussion forum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d8e575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8', '50'],\n",
       " ['74', '59'],\n",
       " ['31', '73'],\n",
       " ['45', '79'],\n",
       " ['24', '10'],\n",
       " ['41', '66'],\n",
       " ['93', '43'],\n",
       " ['88', '4'],\n",
       " ['28', '30'],\n",
       " ['41', '13']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file = open(\"C3W1_jobs.txt\", \"r\")\n",
    "lines = text_file.readlines()\n",
    "data1 = [i.strip().split(\" \") for i in lines[1:]]\n",
    "text_file.close()\n",
    "data1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb11d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 1],\n",
       " [100, 3],\n",
       " [100, 3],\n",
       " [99, 2],\n",
       " [99, 2],\n",
       " [98, 1],\n",
       " [98, 2],\n",
       " [98, 2],\n",
       " [98, 2],\n",
       " [99, 4]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1sort = sorted(data1,key=lambda x:(int(x[0]) - int(x[1]),int(x[0])),reverse=True)\n",
    "data1sort = [[int(i[0]),int(i[1])] for i in data1sort]\n",
    "data1sort[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8285fe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part1 result: 69119377652\n"
     ]
    }
   ],
   "source": [
    "res = 0\n",
    "curr_time = 0\n",
    "for i in data1sort:\n",
    "    curr_time += i[1]\n",
    "    res += i[0] * curr_time\n",
    "print(\"Part1 result: \" + str(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d93e1c",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "For this problem, use the same data set as in the previous problem.\n",
    "\n",
    "Your task now is to run the greedy algorithm that schedules jobs (optimally) in decreasing order of the ratio (weight/length).  In this algorithm, it does not matter how you break ties.  You should report the sum of weighted completion times of the resulting schedule --- a positive integer --- in the box below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20f5491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 1],\n",
       " [98, 1],\n",
       " [95, 1],\n",
       " [95, 1],\n",
       " [93, 1],\n",
       " [93, 1],\n",
       " [92, 1],\n",
       " [88, 1],\n",
       " [87, 1],\n",
       " [86, 1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1sort2 = sorted(data1,key=lambda x:(float(x[0])/float(x[1]),int(x[0])),reverse=True)\n",
    "data1sort2 = [[int(i[0]),int(i[1])] for i in data1sort2]\n",
    "data1sort2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ea1dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part2 result: 67311454237\n"
     ]
    }
   ],
   "source": [
    "res = 0\n",
    "curr_time = 0\n",
    "for i in data1sort2:\n",
    "    curr_time += i[1]\n",
    "    res += i[0] * curr_time\n",
    "print(\"Part2 result: \" + str(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57212c",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "In this programming problem you'll code up Prim's minimum spanning tree algorithm.\n",
    "\n",
    "Download the text file below.\n",
    "\n",
    "(See C3W1_edges.txt)\n",
    "\n",
    "This file describes an undirected graph with integer edge costs.  It has the format\n",
    "\n",
    "[number_of_nodes] [number_of_edges]\n",
    "\n",
    "[one_node_of_edge_1] [other_node_of_edge_1] [edge_1_cost]\n",
    "\n",
    "[one_node_of_edge_2] [other_node_of_edge_2] [edge_2_cost]\n",
    "\n",
    "...\n",
    "\n",
    "For example, the third line of the file is \"2 3 -8874\", indicating that there is an edge connecting vertex #2 and vertex #3 that has cost -8874. \n",
    "\n",
    "You should NOT assume that edge costs are positive, nor should you assume that they are distinct.\n",
    "\n",
    "Your task is to run Prim's minimum spanning tree algorithm on this graph.  You should report the overall cost of a minimum spanning tree --- an integer, which may or may not be negative --- in the box below. \n",
    "\n",
    "IMPLEMENTATION NOTES: This graph is small enough that the straightforward O(mn) time implementation of Prim's algorithm should work fine. OPTIONAL: For those of you seeking an additional challenge, try implementing a heap-based version. The simpler approach, which should already give you a healthy speed-up, is to maintain relevant edges in a heap (with keys = edge costs).  The superior approach stores the unprocessed vertices in the heap, as described in lecture.  Note this requires a heap that supports deletions, and you'll probably need to maintain some kind of mapping between vertices and their positions in the heap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069fff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 6807],\n",
       " [2, 3, -8874],\n",
       " [3, 4, -1055],\n",
       " [4, 5, 4414],\n",
       " [5, 6, 1728],\n",
       " [6, 7, -2237],\n",
       " [7, 8, -7507],\n",
       " [8, 9, 7990],\n",
       " [9, 10, -5012],\n",
       " [10, 11, 7353]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file = open(\"C3W1_edges.txt\", \"r\")\n",
    "lines = text_file.readlines()\n",
    "data1_3 = [i.strip().split(\" \") for i in lines[1:]]\n",
    "data1_3 = [[int(j) for j in i] for i in data1_3]\n",
    "text_file.close()\n",
    "\n",
    "# flipped, because undirected graph\n",
    "data1_3 += [[i[1], i[0], i[2]] for i in data1_3]\n",
    "data1_3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "573237b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part3 result: -3612829\n"
     ]
    }
   ],
   "source": [
    "travelled = set([1])\n",
    "notTravelled = set(range(2,max([max(i[0:1]) for i in data1_3])+1))\n",
    "cost = 0\n",
    "\n",
    "while notTravelled:\n",
    "    nextNode = sorted([i for i in data1_3 if i[0] in travelled and i[1] in notTravelled],key=lambda x:(x[2]))[0]\n",
    "    travelled.add(nextNode[1])\n",
    "    notTravelled.remove(nextNode[1])\n",
    "    \n",
    "    cost += nextNode[2]\n",
    "print(\"Part3 result: \" + str(cost))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e0950f",
   "metadata": {},
   "source": [
    "# Programming Exercise 2\n",
    "\n",
    "## Part 1\n",
    "\n",
    "In this programming problem and the next you'll code up the clustering algorithm from lecture for computing a max-spacing kk-clustering.\n",
    "\n",
    "Download the text file below.\n",
    "\n",
    "(See C3W2_clustering1.txt)\n",
    "\n",
    "This file describes a distance function (equivalently, a complete graph with edge costs).  It has the following format:\n",
    "\n",
    "[number_of_nodes]\n",
    "\n",
    "[edge 1 node 1] [edge 1 node 2] [edge 1 cost]\n",
    "\n",
    "[edge 2 node 1] [edge 2 node 2] [edge 2 cost]\n",
    "\n",
    "...\n",
    "\n",
    "There is one edge (i,j) for each choice of 1 <= i < j <= n, where n is the number of nodes.\n",
    "\n",
    "For example, the third line of the file is \"1 3 5250\", indicating that the distance between nodes 1 and 3 (equivalently, the cost of the edge (1,3)) is 5250.  You can assume that distances are positive, but you should NOT assume that they are distinct.\n",
    "\n",
    "Your task in this problem is to run the clustering algorithm from lecture on this data set, where the target number k of clusters is set to 4.  What is the maximum spacing of a 4-clustering?\n",
    "\n",
    "ADVICE: If you're not getting the correct answer, try debugging your algorithm using some small test cases.  And then post them to the discussion forum!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfab5c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124750"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file = open(\"C3W2_clustering1.txt\", \"r\")\n",
    "lines = text_file.readlines()\n",
    "data2_1 = [i.strip().split(\" \") for i in lines[1:]]\n",
    "data2_1 = [[int(j) for j in i] for i in data2_1]\n",
    "text_file.close()\n",
    "len(data2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0360847c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 348, 1],\n",
       " [12, 373, 1],\n",
       " [27, 487, 1],\n",
       " [60, 175, 1],\n",
       " [79, 138, 1],\n",
       " [85, 333, 1],\n",
       " [92, 387, 1],\n",
       " [98, 112, 1],\n",
       " [130, 420, 1],\n",
       " [182, 225, 1]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_1sort = sorted(data2_1,key=lambda x:(x[2]))\n",
    "data2_1sort[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b169172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between each cluster: {(102, 384): 123, (102, 414): 106, (102, 462): 107, (384, 414): 1162, (384, 462): 1641, (414, 462): 746}\n",
      "Maximum distance (Rightful Part1 Answer): 1641\n",
      "Minimum distance (Actual Part1 Answer): 106\n"
     ]
    }
   ],
   "source": [
    "# Initialize leader pointer array, and count of \n",
    "leaderarr = list(range(1+max([i[1] for i in data2_1sort])))\n",
    "countarr = [1 for i in leaderarr]\n",
    "for i in data2_1sort:\n",
    "    if len(set(leaderarr)) == 5:\n",
    "        break\n",
    "    \n",
    "    # get leader pointer of both nodes\n",
    "    leftleader = leaderarr[i[0]]\n",
    "    rightleader = leaderarr[i[1]]\n",
    "    \n",
    "    # get count of both leader\n",
    "    leftcount = countarr[leftleader]\n",
    "    rightcount = countarr[rightleader]\n",
    "    \n",
    "    # replace the leader with smaller count\n",
    "    if leftcount < rightcount:\n",
    "        countarr[leftleader] = 0\n",
    "        countarr[rightleader] += leftcount\n",
    "        for j in range(len(leaderarr)):\n",
    "            if leaderarr[j] == leftleader:\n",
    "                leaderarr[j] = rightleader\n",
    "    else:\n",
    "        countarr[rightleader] = 0\n",
    "        countarr[leftleader] += rightcount\n",
    "        for j in range(len(leaderarr)):\n",
    "            if leaderarr[j] == rightleader:\n",
    "                leaderarr[j] = leftleader\n",
    "\n",
    "# Loop through all data, track minimum of all combinations of leaders\n",
    "clusterdist = {}\n",
    "for i in data2_1:\n",
    "    leftleader = leaderarr[i[0]]\n",
    "    rightleader = leaderarr[i[1]]\n",
    "    if leftleader != rightleader:\n",
    "        key = (min(leftleader, rightleader), (max(leftleader, rightleader)))\n",
    "        if key in clusterdist.keys():\n",
    "            clusterdist[key] = min(i[2], clusterdist[key])\n",
    "        else:\n",
    "            clusterdist[key] = i[2]\n",
    "    \n",
    "print(\"Distance between each cluster: \" + str(clusterdist))\n",
    "print(\"Maximum distance (Rightful Part1 Answer): \" + str(max(clusterdist.values())))\n",
    "print(\"Minimum distance (Actual Part1 Answer): \" + str(min(clusterdist.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d794c60",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "In this question your task is again to run the clustering algorithm from lecture, but on a MUCH bigger graph.  So big, in fact, that the distances (i.e., edge costs) are only defined implicitly, rather than being provided as an explicit list.\n",
    "\n",
    "The data set is below.\n",
    "\n",
    "(See C3W2_clustering_big.txt)\n",
    "\n",
    "The format is:\n",
    "\n",
    "[# of nodes] [# of bits for each node's label]\n",
    "\n",
    "[first bit of node 1] ... [last bit of node 1]\n",
    "\n",
    "[first bit of node 2] ... [last bit of node 2]\n",
    "\n",
    "...\n",
    "\n",
    "For example, the third line of the file \"0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1\" denotes the 24 bits associated with node #2.\n",
    "\n",
    "The distance between two nodes u and v in this problem is defined as the Hamming distance--- the number of differing bits --- between the two nodes' labels.  For example, the Hamming distance between the 24-bit label of node #2 above and the label \"0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1\" is 3 (since they differ in the 3rd, 7th, and 21st bits).\n",
    "\n",
    "The question is: what is the largest value of k such that there is a k-clustering with spacing at least 3?  That is, how many clusters are needed to ensure that no pair of nodes with all but 2 bits in common get split into different clusters?\n",
    "\n",
    "NOTE: The graph implicitly defined by the data file is so big that you probably can't write it out explicitly, let alone sort the edges by cost.  So you will have to be a little creative to complete this part of the question.  For example, is there some way you can identify the smallest distances without explicitly looking at every pair of nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7774066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file = open(\"C3W2_clustering_big.txt\", \"r\")\n",
    "lines = text_file.readlines()\n",
    "data2_2 = [int(i.strip().replace(\" \",\"\"), 2) for i in lines[1:]]\n",
    "text_file.close()\n",
    "len(data2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f61c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks: 301\n",
      "Number of unions (Part2 Answer): 6118\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from networkx.utils import UnionFind\n",
    "\n",
    "nodes = {}\n",
    "for node, num in enumerate(data2_2):\n",
    "    if num not in nodes:\n",
    "        nodes[num] = set()\n",
    "    nodes[num].add(node)\n",
    "    \n",
    "\n",
    "uf = UnionFind(range(len(data2_2)))\n",
    "\n",
    "# masks contain bitwise difference of =1, =2 and =0 (ie 1 bit at different positions, 2 bit at different positions and all 0.\n",
    "# Hence, len(distances) is hence 24 + 24C2 + 1 = 301\n",
    "masks = [1 << i for i in range(24)]\n",
    "masks += [(1 << ix_1) ^ (1 << ix_2) for (ix_1, ix_2) in itertools.combinations(range(24), 2)]\n",
    "masks.append(0)\n",
    "print(\"Number of masks: \" + str(len(masks)))\n",
    "\n",
    "# for every mask, do XOR on keys (ie when mask is 1, change bit)\n",
    "# If the result is also in the key set, union all combination\n",
    "for mask in masks:\n",
    "    for number in nodes.keys():\n",
    "        if (number ^ mask) in nodes:\n",
    "            for node_from in nodes[number]:\n",
    "                for node_to in nodes[number ^ mask]:\n",
    "                    uf.union(node_from, node_to)\n",
    "print(\"Number of unions (Part2 Answer): \" + str(len(list(uf.to_sets()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf22134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
